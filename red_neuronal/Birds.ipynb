{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "from keras.preprocessing.image import ImageDataGenerator \r\n",
    "# https://keras.io/api/preprocessing/image/#image-data-preprocessing\r\n",
    "from keras.applications.imagenet_utils import preprocess_input\r\n",
    "\r\n",
    "from keras.models import VGG19\r\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\r\n",
    "from keras.activations import relu, sigmoid\r\n",
    "\r\n",
    "from keras.optimizers import Adam\r\n",
    "from keras.losses import categorical_hinge\r\n",
    "from keras.metrics import accuracy\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "pathTrain = './../dataset/train'\r\n",
    "pathTest = './../dataset/test'\r\n",
    "\r\n",
    "if (os.path.exists(pathTrain) and os.path.exists(pathTest)):\r\n",
    "    print('OK')\r\n",
    "else:\r\n",
    "    print('No existen carpetas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39364 images belonging to 275 classes.\n",
      "Found 1375 images belonging to 275 classes.\n"
     ]
    }
   ],
   "source": [
    "images_increased = 5\r\n",
    "width_shape = 224\r\n",
    "height_shape = 224\r\n",
    "batch_size = 32\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(\r\n",
    "    rotation_range=20, # rota 20 grados\r\n",
    "    zoom_range=0.2, # zoom\r\n",
    "    width_shift_range=0.1, # desplazar 10%\r\n",
    "    height_shift_range=0.1,  # desplazar 10%\r\n",
    "    horizontal_flip=True, # invertir horizontalmente\r\n",
    "    vertical_flip=False,\r\n",
    "    preprocessing_function=preprocess_input\r\n",
    ")\r\n",
    "\r\n",
    "valid_datagen = ImageDataGenerator(    \r\n",
    "    rotation_range=20,\r\n",
    "    zoom_range=0.2,\r\n",
    "    width_shift_range=0.1,\r\n",
    "    height_shift_range=0.1,\r\n",
    "    horizontal_flip=True,\r\n",
    "    vertical_flip=False,\r\n",
    "    preprocessing_function=preprocess_input)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(  \r\n",
    "    pathTrain,\r\n",
    "    target_size=(width_shape, height_shape),\r\n",
    "    batch_size=batch_size,\r\n",
    "    class_mode='categorical')\r\n",
    "\r\n",
    "validation_generator = valid_datagen.flow_from_directory(  \r\n",
    "    pathTest,\r\n",
    "    target_size=(width_shape, height_shape),\r\n",
    "    batch_size=batch_size,\r\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 33)      924       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 32)      9536      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 106, 106, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 179776)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11505728  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 23)                1495      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 11,573,358\n",
      "Trainable params: 11,573,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG19()\r\n",
    "\r\n",
    "inputShape = (height_shape, width_shape, 3)\r\n",
    "\r\n",
    "model.add(Conv2D(filters=33, kernel_size=(3,3), input_shape=inputShape))\r\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3)))\r\n",
    "model.add(MaxPool2D())\r\n",
    "\r\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3)))\r\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3)))\r\n",
    "model.add(MaxPool2D())\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "\r\n",
    "model.add(Dense(64, activation=relu))\r\n",
    "model.add(Dense(23, activation=relu))\r\n",
    "model.add(Dense(10, activation=relu))\r\n",
    "model.add(Dense(1, activation=sigmoid))\r\n",
    "\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001)\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    optimizer=adam,\r\n",
    "    loss=categorical_hinge,\r\n",
    "    metrics=[accuracy]\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 185s 3s/step - loss: 1.0000 - accuracy: 4.5538e-04 - val_loss: 1.0000 - val_accuracy: 5.2893e-06\n",
      "Epoch 2/10\n",
      "38/50 [=====================>........] - ETA: 34s - loss: 1.0000 - accuracy: 0.0015"
     ]
    }
   ],
   "source": [
    "epoch = 10\r\n",
    "\r\n",
    "history = model.fit(\r\n",
    "    train_generator,\r\n",
    "    steps_per_epoch=50,\r\n",
    "    validation_data=validation_generator,\r\n",
    "    epochs=epoch\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history\n",
    "plt.plot(range(len(history.history['loss'])), history.history['loss'], color='red')\n",
    "plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'], color='blue')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e615f74c41e8e1ca263dcf64b553c2a8dc914662b9a5cd387d2912ba1abbb957"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}